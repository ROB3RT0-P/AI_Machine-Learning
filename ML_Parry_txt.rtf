{\rtf1\ansi\ansicpg1252\cocoartf2638
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\fswiss\fcharset0 Helvetica;\f2\fnil\fcharset0 Menlo-Regular;
}
{\colortbl;\red255\green255\blue255;\red25\green25\blue25;\red15\green112\blue16;\red242\green242\blue242;
\red148\green0\blue242;\red8\green0\blue255;}
{\*\expandedcolortbl;;\cssrgb\c12941\c12941\c12941;\cssrgb\c0\c50196\c7451;\cssrgb\c96078\c96078\c96078;
\cssrgb\c65490\c3529\c96078;\cssrgb\c5490\c0\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\b\fs28 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Artificial Intelligence/Machine Learning - Coursework
\f1\b0 \

\f0\b Robert Parry - 19028639
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 1)
\f1\b0 \'a0Filesize - based features ~ Working\

\f0\b 2)
\f1\b0 \'a0Brightness - based features ~ Working\

\f0\b 3)
\f1\b0 \'a0Edge - based features ~ Not fully working\

\f0\b 4)
\f1\b0 \'a0HOG1 - based features ~ Working\

\f0\b 5)
\f1\b0 \'a0BoVW2 - based features ~ Not fully working - worked once then stopped\

\f0\b 6)
\f1\b0 \'a0CNN - based features\
   
\f0\b \'a0i)
\f1\b0 \'a0resnet50 ~ Working\
   
\f0\b \'a0ii)
\f1\b0 \'a0alexnet ~ Working\

\f0\b 7)
\f1\b0 \'a0Extra - KNN ~ Working\

\f0\b 8)
\f1\b0 \'a0Functions\
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 1. Filesize-based features
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2 \cf3 \cb4 \strokec3 %Reading the file sizes of each picture, then inputting them into a table\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 % load the dataset:\cf2 \cb1 \strokec2 \
\cb4     data = readcell(\cf5 \strokec5 'MerchData.csv'\cf2 \strokec2 );\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 % Create the dataset array\cf2 \cb1 \strokec2 \
\cb4     data(1:1:10, 1:1:end)\cb1 \
\cb4     data(1, :) = [];\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 % Populate the array with the data\cf2 \cb1 \strokec2 \
\cb4     data = data(randperm(size(data,1)), :);\cb1 \
\cb4     \cb1 \
\
\
\cb4     rng(0); \cf3 \strokec3 % please leave this re-seeding of the random number generator in place so we can compare results\cf2 \cb1 \strokec2 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 % Set the variable values using 'data'\cf2 \cb1 \strokec2 \
\cb4     nTest = round(0.4 * size(data,1))\cb1 \
\cb4     data_test = data(1:1:nTest, :);\cb1 \
\cb4     data_train = data(nTest+1:1:end, :);\cb1 \
\cb4     \cb1 \
\cb4    \cb1 \
\cb4     \cf3 \strokec3 %Set the label index based on how many label columns needed\cf2 \cb1 \strokec2 \
\cb4     label_index = 2;\cb1 \
\cb4     \cf3 \strokec3 %Set test_labels/examples data using the previous data test and train vars\cf2 \cb1 \strokec2 \
\cb4     test_labels = categorical(data_test(:, label_index));\cb1 \
\cb4     test_examples = cell2mat(data_test(:, 1:end~=label_index));\cb1 \
\cb4     \cf3 \strokec3 %Set train_labels/examples data using the previous data test and train vars\cf2 \cb1 \strokec2 \
\cb4     train_labels = categorical(data_train(:, label_index));\cb1 \
\cb4     train_examples = cell2mat(data_train(:, 1:end~=label_index));\cb1 \
\cb4     \cb1 \
\cb4         \cb1 \
\cb4     \cf3 \strokec3 %Set var 'm_knn'  to use the function for 'knn' using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     m_knn = fitcknn(train_examples, train_labels)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Set var 'm_nb'  to use the function for 'cnb' using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     m_nb = fitcnb(train_examples, train_labels)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Set var 'm_dt'  to use the function for 'tree' using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     m_dt = fitctree(train_examples, train_labels)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Set var 'm_ann'  to use the function for 'net' using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     m_ann = fitcnet(train_examples, train_labels)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Set var 'm_svm'  to use the function for 'ecoc' using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     m_svm = fitcecoc(train_examples, train_labels)\cb1 \
\cb4     \cb1 \
\cb4     \cb1 \
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Prediction Setup \cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     predictions = predict(m_knn, test_examples);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     \cf3 \strokec3 %Set var 'predictions1'  to use the function for predict using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     predictions1 = predict(m_nb, test_examples);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     \cf3 \strokec3 %Set var 'predictions2'  to use the function for predict using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     predictions2 = predict(m_dt, test_examples);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     \cf3 \strokec3 %Set var 'predictions3'  to use the function for predict using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     predictions3 = predict(m_ann, test_examples);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     \cf3 \strokec3 %Set var 'predictions4'  to use the function for predict using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     predictions4 = predict(m_svm, test_examples);\cb1 \
\cb4     \cb1 \
\cb4     \cb1 \
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %KNN Evaluation\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cb1 \
\cb4     \cf3 \strokec3 %Create a confusion matrix using 'test_labels' and 'predictions'\cf2 \cb1 \strokec2 \
\cb4     [c, order] = confusionmat(test_labels, predictions)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Create and display a confusion chart using 'test labels' and predictions\cf2 \cb1 \strokec2 \
\cb4     confusionchart(test_labels, predictions)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Output accuracy\cf2 \cb1 \strokec2 \
\cb4     p = sum(diag(c)) / sum(c(1:1:end))\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %NB Evaluation\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4        \cb1 \
\cb4     [c, order] = confusionmat(test_labels, predictions1)\cb1 \
\cb4     \cb1 \
\cb4     \cb1 \
\cb4     confusionchart(test_labels, predictions1)\cb1 \
\cb4     \cb1 \
\cb4     \cb1 \
\cb4     p = sum(diag(c)) / sum(c(1:1:end))\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %DT Evaluation\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4        \cb1 \
\cb4     [c, order] = confusionmat(test_labels, predictions2)\cb1 \
\cb4     \cb1 \
\cb4    \cb1 \
\cb4     confusionchart(test_labels, predictions2)\cb1 \
\cb4     \cb1 \
\cb4     \cb1 \
\cb4     p = sum(diag(c)) / sum(c(1:1:end))\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %ANN Evaluation\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4      \cb1 \
\cb4     [c, order] = confusionmat(test_labels, predictions3)\cb1 \
\cb4        \cb1 \
\cb4     confusionchart(test_labels, predictions3)\cb1 \
\cb4     \cb1 \
\cb4     p = sum(diag(c)) / sum(c(1:1:end))\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %SVM Evaluation\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     [c, order] = confusionmat(test_labels, predictions4)\cb1 \
\cb4     \cb1 \
\cb4     confusionchart(test_labels, predictions4)\cb1 \
\cb4     \cb1 \
\cb4     p = sum(diag(c)) / sum(c(1:1:end))\cb1 \
\
\
\
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 2. Brightness-based features     
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2 \cf3 \cb4 \strokec3 %Data    \cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Check the dataset is present:\cf2 \cb1 \strokec2 \
\cb4     \cf6 \strokec6 if \cf2 \strokec2 ~exist(\cf5 \strokec5 './MerchData'\cf2 \strokec2 , \cf5 \strokec5 'dir'\cf2 \strokec2 )\cb1 \
\cb4         error(\cf5 \strokec5 'You need to download MerchData.zip from Moodle and unzip it into the same directory as this live script'\cf2 \strokec2 );\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Working with the datastore  \cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Create the imagedatastore object:\cf2 \cb1 \strokec2 \
\cb4     imds = imageDatastore(\cf5 \strokec5 'MerchData'\cf2 \strokec2 , \cf5 \strokec5 'IncludeSubfolders'\cf2 \strokec2 , true);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 % loop over all the images extracting their size\cf2 \cb1 \strokec2 \
\cb4     grow = [];\cb1 \
\cb4     imds.reset();\cb1 \
\cb4     \cf6 \strokec6 while \cf2 \strokec2 hasdata(imds)\cb1 \
\cb4         im = imds.read();\cb1 \
\cb4         grow(end+1,:) = size(im); \cf3 \strokec3 % store the dimensions of the image (height, width, depth)\cf2 \cb1 \strokec2 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\cb4     \cb1 \
\cb4     size(grow)\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Splitting image dataset\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     rng(0);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Using 'MerchData' to populate 'imds'\cf2 \cb1 \strokec2 \
\cb4     imds = imageDatastore(\cf5 \strokec5 'MerchData'\cf2 \strokec2 , \cf5 \strokec5 'IncludeSubfolders'\cf2 \strokec2 , true, \cf5 \strokec5 'LabelSource'\cf2 \strokec2 ,\cf5 \strokec5 'foldernames'\cf2 \strokec2 )\cb1 \
\cb4     [training, testing] = splitEachLabel(imds, 0.6, \cf5 \strokec5 'randomize'\cf2 \strokec2 );\cb1 \
\
\
\cb4     \cf3 \strokec3 %Set 'im' to the first image from training\cf2 \cb1 \strokec2 \
\cb4     im = training.readimage(1)\cb1 \
\cb4     \cf3 \strokec3 %im = my_im2gray(im)\cf2 \cb1 \strokec2 \
\cb4     imshow(im);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Use the size function with 'im' as the input\cf2 \cb1 \strokec2 \
\cb4     size(im)\cb1 \
\
\
\cb4     \cf3 \strokec3 %Convert the loaded image from rgb(colour) to greyscale(black&white)\cf2 \cb1 \strokec2 \
\cb4     im = im2gray(im);\cb1 \
\cb4     size(im)\cb1 \
\cb4     x = size(im)\cb1 \
\cb4     n = x(1,2) * x(1,2)\cb1 \
\cb4     \cf3 \strokec3 %Output the loaded image\cf2 \cb1 \strokec2 \
\cb4     imshow(im);\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Testing code\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Read the image and put it in an array\cf2 \cb1 \strokec2 \
\cb4     my2dimagearray = imread(\cf5 \strokec5 'cameraman.tif'\cf2 \strokec2 );\cb1 \
\cb4     imshow(my2dimagearray);\cb1 \
\
\
\cb4     \cf3 \strokec3 %Changing the brightness value of the 100th value\cf2 \cb1 \strokec2 \
\cb4     my2dimagearray(100,50) = 255;\cb1 \
\cb4     imshow(my2dimagearray)\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 % %Working with the image data - testing\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     \cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     %Load the first image from the dataset into the var 'im'\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     im = training.readimage(1)\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     imshow(im);\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     \cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     %calculate average brightness of an image\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     brightness = mean2(im)\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     \cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     %Create and populate the array 'imageArray' with the data from 'im'\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     imageArray = []\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     imageArray = im\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     \cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     %Create and populate the var 'summedImage' with the summed values from 'ImageArray'\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     summedImage = sum(imageArray(),"all")\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     \cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %     finbri = summedImage / n\cf2 \cb1 \strokec2 \
\
\
\
\
\
\
\cf3 \cb4 \strokec3 %Setting up and running the training data\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Populate the training data using the images in the dataset and extracting\cf2 \cb1 \strokec2 \
\cb4     \cf3 \strokec3 %the relavent data using the 'get_brightness()' function\cf2 \cb1 \strokec2 \
\cb4     train_examples = [];\cb1 \
\cb4     \cf6 \strokec6 while \cf2 \strokec2 hasdata(training)\cb1 \
\cb4     \cf3 \strokec3 %Convert the training image to greyscale\cf2 \cb1 \strokec2 \
\cb4     im = im2gray(training.read());\cb1 \
\cb4     \cf3 \strokec3 %Populate 'train_examples' using the 'get_brightness' function\cf2 \cb1 \strokec2 \
\cb4     train_examples(end+1,:) = get_brightness(im);\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\cb4     train_labels = training.Labels;\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Setting up and running the testing data\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Populate the test examples using the images in the dataset and extracting\cf2 \cb1 \strokec2 \
\cb4     \cf3 \strokec3 %the relavent data using the 'get_brightness()' function\cf2 \cb1 \strokec2 \
\cb4     test_examples = [];\cb1 \
\cb4     \cf6 \strokec6 while \cf2 \strokec2 hasdata(testing)\cb1 \
\cb4     \cf3 \strokec3 %Set 'im' to a greyscale version of the training image loaded\cf2 \cb1 \strokec2 \
\cb4     im = im2gray(testing.read());\cb1 \
\cb4     \cf3 \strokec3 %populate the 'test_examples' with the image data that has been run\cf2 \cb1 \strokec2 \
\cb4     \cf3 \strokec3 %through the 'get_brightness()' function\cf2 \cb1 \strokec2 \
\cb4     test_examples(end+1,:) = get_brightness(im);\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\cb4     \cf3 \strokec3 %Copy the testing label data over\cf2 \cb1 \strokec2 \
\cb4     test_labels = testing.Labels;\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Check the data is present and correct by outputting it\cf2 \cb1 \strokec2 \
\cb4     test_examples\cb1 \
\cb4     \cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Setting up Classifier and Prediction\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Set var 'm_knn'  to use the function for 'knn' using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     m_knn = fitcknn(train_examples, train_labels , \cf5 \strokec5 'NumNeighbors'\cf2 \strokec2 , 3)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Set var 'predictions'  to use the function for predict using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     predictions = predict(m_knn, test_examples);\cb1 \
\
\
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Evaluate classifiers performance\cf2 \cb1 \strokec2 \
\
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Create a confusion matrix using 'test_labels' and 'predictions'\cf2 \cb1 \strokec2 \
\cb4     [c, order] = confusionmat(test_labels, predictions)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Create and display a confusion chart using 'test labels' and predictions\cf2 \cb1 \strokec2 \
\cb4     confusionchart(test_labels, predictions)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Output accuracy\cf2 \cb1 \strokec2 \
\cb4     p = sum(diag(c)) / sum(c(1:1:end))\cb1 \
\
\
\
\
\
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 3. Edge-based features
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2 \cf3 \cb4 \strokec3 %Check the dataset is present:\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf6 \strokec6 if \cf2 \strokec2 ~exist(\cf5 \strokec5 './MerchData'\cf2 \strokec2 , \cf5 \strokec5 'dir'\cf2 \strokec2 )\cb1 \
\cb4         error(\cf5 \strokec5 'You need to download MerchData.zip from Moodle and unzip it into the same directory as this live script'\cf2 \strokec2 );\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\cb4 rng(0);\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Working with the datastore  \cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Create the imagedatastore object:\cf2 \cb1 \strokec2 \
\cb4     imds = imageDatastore(\cf5 \strokec5 'MerchData'\cf2 \strokec2 , \cf5 \strokec5 'IncludeSubfolders'\cf2 \strokec2 , true);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 % loop over all the images extracting their size\cf2 \cb1 \strokec2 \
\cb4     grow = [];\cb1 \
\cb4     imds.reset();\cb1 \
\cb4     \cf6 \strokec6 while \cf2 \strokec2 hasdata(imds)\cb1 \
\cb4         im = imds.read();\cb1 \
\cb4         grow(end+1,:) = size(im); \cf3 \strokec3 % store the dimensions of the image (height, width, depth)\cf2 \cb1 \strokec2 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 % here's the data we're left with...\cf2 \cb1 \strokec2 \
\cb4     size(grow)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %set 'im' to image 1\cf2 \cb1 \strokec2 \
\cb4     im = training.readimage(1);\cb1 \
\cb4     imshow(im);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Convert image to greyscale\cf2 \cb1 \strokec2 \
\cb4     im = im2gray(im);\cb1 \
\cb4     imshow(im);\cb1 \
\cb4     \cb1 \
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Setting up and running the training data\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     train_examples = [];\cb1 \
\cb4     \cf3 \strokec3 %Loop until all of the training data has been used\cf2 \cb1 \strokec2 \
\cb4     \cf6 \strokec6 while \cf2 \strokec2 hasdata(training)\cb1 \
\cb4     \cf3 \strokec3 %Convert the training image to greyscale\cf2 \cb1 \strokec2 \
\cb4     im = im2gray(training.read());\cb1 \
\cb4     \cf3 \strokec3 %Populate train_exaples using the 'get_edges' function\cf2 \cb1 \strokec2 \
\cb4     train_examples(end+1,:) = get_edges(im);\cb1 \
\cb4     \cf6 \strokec6 end \cf2 \cb1 \strokec2 \
\
\
\cb4     \cf3 \strokec3 %Set 'train_labels' equal to 'training.labels'\cf2 \cb1 \strokec2 \
\cb4     train_labels = training.Labels;\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Setting up and running the testing data\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     test_examples = [];\cb1 \
\cb4     \cf6 \strokec6 while \cf2 \strokec2 hasdata(testing)\cb1 \
\cb4     \cf3 \strokec3 %Set 'im' to a greyscale version of the training image loaded\cf2 \cb1 \strokec2 \
\cb4     im = im2gray(testing.read());\cb1 \
\cb4     \cf3 \strokec3 %Populate 'test_examples' using the 'get_edges' function\cf2 \cb1 \strokec2 \
\cb4     test_examples(end+1,:) = get_edges(im);\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\cb4     \cf3 \strokec3 %Set the 'test_labels' equal to 'training.labels'\cf2 \cb1 \strokec2 \
\cb4     test_labels = testing.Labels;\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Setting up Classifier and Prediction\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Set var 'm_knn'  to use the function for 'knn' using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     m_knn = fitcknn(train_examples, train_labels, \cf5 \strokec5 'NumNeighbors'\cf2 \strokec2 , 3)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     predictions = predict(m_knn, test_examples);\cb1 \
\
\
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Evaluate classifiers performance\cf2 \cb1 \strokec2 \
\
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Create a confusion matrix using 'test_labels' and 'predictions'\cf2 \cb1 \strokec2 \
\cb4     [c, order] = confusionmat(test_labels, predictions)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Create and display a confusion chart using 'test labels' and predictions\cf2 \cb1 \strokec2 \
\cb4     confusionchart(test_labels, predictions)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Output accuracy\cf2 \cb1 \strokec2 \
\cb4     p = sum(diag(c)) / sum(c(1:1:end))\cb1 \
\
\
\
\
\
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 4. HOG-based features
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2 \cf3 \cb4 \strokec3 %Check the dataset is present:\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf6 \strokec6 if \cf2 \strokec2 ~exist(\cf5 \strokec5 './MerchData'\cf2 \strokec2 , \cf5 \strokec5 'dir'\cf2 \strokec2 )\cb1 \
\cb4         error(\cf5 \strokec5 'You need to download MerchData.zip from Moodle and unzip it into the same directory as this live script'\cf2 \strokec2 );\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\cb4 rng(0);\cf3 \strokec3 %Reset the random number generator\cf2 \cb1 \strokec2 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Working with the datastore  \cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Create the imagedatastore object:\cf2 \cb1 \strokec2 \
\cb4     imds = imageDatastore(\cf5 \strokec5 'MerchData'\cf2 \strokec2 , \cf5 \strokec5 'IncludeSubfolders'\cf2 \strokec2 , true);\cb1 \
\
\
\cb4     \cf3 \strokec3 % loop over all the images extracting their size\cf2 \cb1 \strokec2 \
\cb4     grow = [];\cb1 \
\cb4     imds.reset();\cb1 \
\cb4     \cf6 \strokec6 while \cf2 \strokec2 hasdata(imds)\cb1 \
\cb4         im = imds.read();\cb1 \
\cb4         grow(end+1,:) = size(im); \cf3 \strokec3 % store the dimensions of the image (height, width, depth)\cf2 \cb1 \strokec2 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\cb4     size(grow)\cb1 \
\cb4     \cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Splitting image dataset\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     imds = imageDatastore(\cf5 \strokec5 'MerchData'\cf2 \strokec2 , \cf5 \strokec5 'IncludeSubfolders'\cf2 \strokec2 , true, \cf5 \strokec5 'LabelSource'\cf2 \strokec2 ,\cf5 \strokec5 'foldernames'\cf2 \strokec2 )\cb1 \
\cb4     [training, testing] = splitEachLabel(imds, 0.6, \cf5 \strokec5 'randomize'\cf2 \strokec2 );\cb1 \
\cb4     \cf3 \strokec3 % <my comment removed>:\cf2 \cb1 \strokec2 \
\cb4     im = training.readimage(1);\cb1 \
\cb4     imshow(im);\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 % write your code on the lines below:\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4 im = im2gray(im);\cb1 \
\cb4 imshow(im);\cb1 \
\
\
\cb4 [Gx, Gy] = imgradientxy(im, \cf5 \strokec5 'Prewitt'\cf2 \strokec2 );\cb1 \
\cb4 [Gmag, Gdir] = imgradient(Gx, Gy);\cb1 \
\
\
\cb4 imagesc(Gmag);\cb1 \
\cb4 imagesc(Gdir);\cb1 \
\
\
\cb4 CELLSIZE = [16 16];\cb1 \
\cb4 [h, v] = extractHOGFeatures(im, \cf5 \strokec5 'CellSize'\cf2 \strokec2 , CELLSIZE, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb4 \strokec5 'BlockSize'\cf2 \strokec2 , [floor(size(im,1)/CELLSIZE(1)) floor(size(im,2)/CELLSIZE(2))], \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cf5 \cb4 \strokec5 'UseSignedOrientation'\cf2 \strokec2 , true);\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb4 imshow(im);\cb1 \
\cb4 hold(\cf5 \strokec5 'on'\cf2 \strokec2 );\cb1 \
\cb4 v.plot();\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Setting up and running the training data\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     train_examples = [];\cb1 \
\cb4     \cf3 \strokec3 %Loop until all of the training data has been used\cf2 \cb1 \strokec2 \
\cb4     \cf6 \strokec6 while \cf2 \strokec2 hasdata(training)\cb1 \
\cb4     \cf3 \strokec3 %Set 'im' to a greyscale version of the training image loaded\cf2 \cb1 \strokec2 \
\cb4     im = im2gray(training.read());\cb1 \
\cb4     \cf3 \strokec3 %Populate 'train_examples' using the 'get_hogs' function\cf2 \cb1 \strokec2 \
\cb4     train_examples(end+1,:) = get_hogs(im);\cb1 \
\cb4     \cf6 \strokec6 end \cf2 \cb1 \strokec2 \
\cb4    \cb1 \
\cb4     train_labels = training.Labels;\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Setting up and running the testing data\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     test_examples = [];\cb1 \
\cb4     \cf3 \strokec3 %Loop until all of the testing data has been used\cf2 \cb1 \strokec2 \
\cb4     \cf6 \strokec6 while \cf2 \strokec2 hasdata(testing)\cb1 \
\cb4     \cf3 \strokec3 %Set 'im' to a greyscale version of the image loaded\cf2 \cb1 \strokec2 \
\cb4     im = im2gray(testing.read());\cb1 \
\cb4     \cf3 \strokec3 %Populate 'test_examples' using the 'get_hogs' function\cf2 \cb1 \strokec2 \
\cb4     test_examples(end+1,:) = get_hogs(im);\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\cb4     test_labels = testing.Labels;\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Setting up Classifier and Prediction\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Set var 'm_knn'  to use the function for 'knn' using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     m_knn = fitcknn(train_examples, train_labels , \cf5 \strokec5 'NumNeighbors'\cf2 \strokec2 , 3)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     predictions = predict(m_knn, test_examples);\cb1 \
\
\
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Evaluate classifiers performance\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Create a confusion matrix using 'test_labels' and 'predictions'\cf2 \cb1 \strokec2 \
\cb4     [c, order] = confusionmat(test_labels, predictions)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Create and display a confusion chart using 'test labels' and predictions\cf2 \cb1 \strokec2 \
\cb4     confusionchart(test_labels, predictions)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Output accuracy\cf2 \cb1 \strokec2 \
\cb4     p = sum(diag(c)) / sum(c(1:1:end))\cb1 \
\
\
\
\
\
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 5. BoVW-based features
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2 \cf3 \cb4 \strokec3 %Check the dataset is present:\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf6 \strokec6 if \cf2 \strokec2 ~exist(\cf5 \strokec5 './MerchData'\cf2 \strokec2 , \cf5 \strokec5 'dir'\cf2 \strokec2 )\cb1 \
\cb4         error(\cf5 \strokec5 'You need to download MerchData.zip from Moodle and unzip it into the same directory as this live script'\cf2 \strokec2 );\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Reset the random number generator to 0\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4 rng(0);\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Working with the datastore    \cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Create the imagedatastore object:\cf2 \cb1 \strokec2 \
\cb4     imds = imageDatastore(\cf5 \strokec5 'MerchData'\cf2 \strokec2 , \cf5 \strokec5 'IncludeSubfolders'\cf2 \strokec2 , true);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 % loop over all the images extracting their size\cf2 \cb1 \strokec2 \
\cb4     grow = [];\cb1 \
\cb4     imds.reset();\cb1 \
\cb4     \cf6 \strokec6 while \cf2 \strokec2 hasdata(imds)\cb1 \
\cb4         im = imds.read();\cb1 \
\cb4         grow(end+1,:) = size(im); \cf3 \strokec3 % store the dimensions of the image (height, width, depth)\cf2 \cb1 \strokec2 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\cb4     \cb1 \
\
\
\cb4     size(grow)\cb1 \
\
\
\cb4     \cf3 \strokec3 %set 'im' to the first training image\cf2 \cb1 \strokec2 \
\cb4     im = training.readimage(1);\cb1 \
\cb4     imshow(im);\cb1 \
\cb4     \cb1 \
\cb4     im = im2gray(im);\cb1 \
\cb4     \cb1 \
\cb4     H = get_hogs(im);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Testing words.encode\cf2 \cb1 \strokec2 \
\cb4     train_examples(end+1,:) = words.encode(im);\cb1 \
\cb4     train_examples\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Setting up and running the training data\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     train_examples = [];\cb1 \
\cb4     \cf3 \strokec3 %Loop until all of the training data has been used\cf2 \cb1 \strokec2 \
\cb4     \cf6 \strokec6 while \cf2 \strokec2 hasdata(training)\cb1 \
\cb4     \cf3 \strokec3 %Set 'im' to a greyscale version of the training image loaded\cf2 \cb1 \strokec2 \
\cb4     im = im2gray(training.read());\cb1 \
\cb4     \cf3 \strokec3 % you can call the .encode() method directly (rather than your own function):\cf2 \cb1 \strokec2 \
\cb4     train_examples(end+1,:) = words.encode(im);\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\cb4     \cf3 \strokec3 % <my comment removed>:\cf2 \cb1 \strokec2 \
\cb4     train_labels = training.Labels;\cb1 \
\cb4     \cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Setting up and running the testing data\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     test_examples = [];\cb1 \
\cb4     \cf3 \strokec3 %Loop until all of the testing data has been used\cf2 \cb1 \strokec2 \
\cb4     \cf6 \strokec6 while \cf2 \strokec2 hasdata(testing)\cb1 \
\cb4     \cf3 \strokec3 % <my comment removed>:\cf2 \cb1 \strokec2 \
\cb4     im = im2gray(testing.read());\cb1 \
\cb4     \cf3 \strokec3 % you can call the .encode() method\cf2 \cb1 \strokec2 \
\cb4     \cf3 \strokec3 % of the object you just created:\cf2 \cb1 \strokec2 \
\cb4     test_examples(end+1,:) = words.encode(im);\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\cb4     \cf3 \strokec3 % <my comment removed>:\cf2 \cb1 \strokec2 \
\cb4     test_labels = testing.Labels;\cb1 \
\cb4     \cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Setting up Classifier and Prediction\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Set var 'm_knn'  to use the function for 'knn' using the two stated variables\cf2 \cb1 \strokec2 \
\cb4     m_knn = fitcknn(train_examples, train_labels , \cf5 \strokec5 'NumNeighbors'\cf2 \strokec2 , 3)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     predictions = predict(m_knn, test_examples);\cb1 \
\
\
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Evaluate classifiers performance\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 % <my comment removed>:\cf2 \cb1 \strokec2 \
\cb4     [c, order] = confusionmat(test_labels, predictions)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Create and display a confusion chart using 'test labels' and predictions\cf2 \cb1 \strokec2 \
\cb4     confusionchart(test_labels, predictions)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 % <my comment removed>:\cf2 \cb1 \strokec2 \
\cb4     p = sum(diag(c)) / sum(c(1:1:end))\cb1 \
\
\
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 6. CNN-based features 
\f1\b0 \

\f0\b i) ResNet50 CNN
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2 \cf3 \cb4 \strokec3 %Relatively accurate 'out the box' using 'MerchData'\cf2 \cb1 \strokec2 \
\
\
\cf3 \cb4 \strokec3 %Load Data\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %Create Datastore\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     unzip(\cf5 \strokec5 'MerchData.zip'\cf2 \strokec2 );\cb1 \
\cb4     imds = imageDatastore(\cf5 \strokec5 'MerchData'\cf2 \strokec2 , \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'IncludeSubfolders'\cf2 \strokec2 ,true, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'LabelSource'\cf2 \strokec2 ,\cf5 \strokec5 'foldernames'\cf2 \strokec2 ); \cb1 \
\cb4     [imdsTrain,imdsValidation] = splitEachLabel(imds,0.7);\cb1 \
\
\
\cb4     \cf3 \strokec3 %Load pretrained network\cf2 \cb1 \strokec2 \
\cb4     net = googlenet;\cb1 \
\
\
\cb4     \cf3 \strokec3 %Display visualisation of the network and it's layers\cf2 \cb1 \strokec2 \
\cb4     analyzeNetwork(net)\cb1 \
\
\
\cb4     net.Layers(1)\cb1 \
\
\
\cb4     inputSize = net.Layers(1).InputSize;\cb1 \
\
\
\cb4     \cf3 \strokec3 %Replace final layers\cf2 \cb1 \strokec2 \
\cb4     lgraph = layerGraph(net);\cb1 \
\
\
\cb4     [learnableLayer,classLayer] = findLayersToReplace(lgraph);\cb1 \
\cb4     [learnableLayer,classLayer]\cb1 \
\
\
\cb4     numClasses = numel(categories(imdsTrain.Labels));\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb4 \strokec6 if \cf2 \strokec2 isa(learnableLayer,\cf5 \strokec5 'nnet.cnn.layer.FullyConnectedLayer'\cf2 \strokec2 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     newLearnableLayer = fullyConnectedLayer(numClasses, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'Name'\cf2 \strokec2 ,\cf5 \strokec5 'new_fc'\cf2 \strokec2 , \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'WeightLearnRateFactor'\cf2 \strokec2 ,10, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'BiasLearnRateFactor'\cf2 \strokec2 ,10);\cb1 \
\cb4     \cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb4 \strokec6 elseif \cf2 \strokec2 isa(learnableLayer,\cf5 \strokec5 'nnet.cnn.layer.Convolution2DLayer'\cf2 \strokec2 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     newLearnableLayer = convolution2dLayer(1,numClasses, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'Name'\cf2 \strokec2 ,\cf5 \strokec5 'new_conv'\cf2 \strokec2 , \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'WeightLearnRateFactor'\cf2 \strokec2 ,10, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'BiasLearnRateFactor'\cf2 \strokec2 ,10);\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb4 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb4 lgraph = replaceLayer(lgraph,learnableLayer.Name,newLearnableLayer);\cb1 \
\
\
\cb4 newClassLayer = classificationLayer(\cf5 \strokec5 'Name'\cf2 \strokec2 ,\cf5 \strokec5 'new_classoutput'\cf2 \strokec2 );\cb1 \
\cb4 lgraph = replaceLayer(lgraph,classLayer.Name,newClassLayer);\cb1 \
\
\
\cb4 figure(\cf5 \strokec5 'Units'\cf2 \strokec2 ,\cf5 \strokec5 'normalized'\cf2 \strokec2 ,\cf5 \strokec5 'Position'\cf2 \strokec2 ,[0.3 0.3 0.4 0.4]);\cb1 \
\cb4 plot(lgraph)\cb1 \
\cb4 ylim([0,10])\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Freeze initial layers\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4 layers = lgraph.Layers;\cb1 \
\cb4 connections = lgraph.Connections;\cb1 \
\
\
\cb4 layers(1:10) = freezeWeights(layers(1:10));\cb1 \
\cb4 lgraph = createLgraphUsingConnections(layers,connections);\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Train Network\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4 pixelRange = [-30 30];\cb1 \
\cb4 scaleRange = [0.9 1.1];\cb1 \
\cb4 imageAugmenter = imageDataAugmenter( \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'RandXReflection'\cf2 \strokec2 ,true, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'RandXTranslation'\cf2 \strokec2 ,pixelRange, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'RandYTranslation'\cf2 \strokec2 ,pixelRange, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'RandXScale'\cf2 \strokec2 ,scaleRange, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'RandYScale'\cf2 \strokec2 ,scaleRange);\cb1 \
\cb4 augimdsTrain = augmentedImageDatastore(inputSize(1:2),imdsTrain, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'DataAugmentation'\cf2 \strokec2 ,imageAugmenter);\cb1 \
\
\
\cb4 augimdsValidation = augmentedImageDatastore(inputSize(1:2),imdsValidation);\cb1 \
\
\
\cb4 miniBatchSize = 10;\cb1 \
\cb4 valFrequency = floor(numel(augimdsTrain.Files)/miniBatchSize);\cb1 \
\cb4 options = trainingOptions(\cf5 \strokec5 'sgdm'\cf2 \strokec2 , \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'MiniBatchSize'\cf2 \strokec2 ,miniBatchSize, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'MaxEpochs'\cf2 \strokec2 ,6, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'InitialLearnRate'\cf2 \strokec2 ,3e-4, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'Shuffle'\cf2 \strokec2 ,\cf5 \strokec5 'every-epoch'\cf2 \strokec2 , \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'ValidationData'\cf2 \strokec2 ,augimdsValidation, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'ValidationFrequency'\cf2 \strokec2 ,valFrequency, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'Verbose'\cf2 \strokec2 ,false, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'Plots'\cf2 \strokec2 ,\cf5 \strokec5 'training-progress'\cf2 \strokec2 );\cb1 \
\
\
\cb4 net = trainNetwork(augimdsTrain,lgraph,options);\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Classify validation images\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4 [YPred,probs] = classify(net,augimdsValidation);\cb1 \
\cb4 accuracy = mean(YPred == imdsValidation.Labels)\cb1 \
\
\
\
\
\cb4 idx = randperm(numel(imdsValidation.Files),4);\cb1 \
\cb4 figure\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb4 \strokec6 for \cf2 \strokec2 i = 1:4\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     subplot(2,2,i)\cb1 \
\cb4     I = readimage(imdsValidation,idx(i));\cb1 \
\cb4     imshow(I)\cb1 \
\cb4     label = YPred(idx(i));\cb1 \
\cb4     title(string(label) + \cf5 \strokec5 ", " \cf2 \strokec2 + num2str(100*max(probs(idx(i),:)),3) + \cf5 \strokec5 "%"\cf2 \strokec2 );\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb4 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
    \
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 ii) AlexNet CNN
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2 \cf3 \cb4 \strokec3 %Alexnet is a convolutional neural network that is 8 layers deep\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %Very accurate out the box using "MerchData"\cf2 \cb1 \strokec2 \
\
\
\cf3 \cb4 \strokec3 %Create image data store\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     imds = imageDatastore(\cf5 \strokec5 'MerchData'\cf2 \strokec2 , \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'IncludeSubfolders'\cf2 \strokec2 ,true, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'LabelSource'\cf2 \strokec2 ,\cf5 \strokec5 'foldernames'\cf2 \strokec2 );\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Split up the traing and testing data\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     [imdsTrain,imdsValidation] = splitEachLabel(imds,0.7,\cf5 \strokec5 'randomized'\cf2 \strokec2 );\cb1 \
\
\
\cb4     numTrainImages = numel(imdsTrain.Labels);\cb1 \
\cb4     idx = randperm(numTrainImages,16);\cb1 \
\cb4     figure\cb1 \
\cb4     \cf6 \strokec6 for \cf2 \strokec2 i = 1:16\cb1 \
\cb4         subplot(4,4,i)\cb1 \
\cb4         I = readimage(imdsTrain,idx(i));\cb1 \
\cb4         imshow(I)\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\cb4     \cb1 \
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Setup and using alexnet convolutional neural network   \cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     net = alexnet;\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Use analyzeNetwork to display the network architecture information about the network layers.\cf2 \cb1 \strokec2 \
\cb4     analyzeNetwork(net)\cb1 \
\
\
\cb4     \cf3 \strokec3 %image input layer using specific size images.\cf2 \cb1 \strokec2 \
\cb4     inputSize = net.Layers(1).InputSize\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Extracting all of the layers except for the last three\cf2 \cb1 \strokec2 \
\cb4     layersTransfer = net.Layers(1:end-3);\cb1 \
\cb4     \cb1 \
\cb4     numClasses = numel(categories(imdsTrain.Labels))\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Replace the last three layers with a fully connected layer, a softmax layer, and a classification output layer.\cf2 \cb1 \strokec2 \
\cb4     layers = [\cb1 \
\cb4         layersTransfer\cb1 \
\cb4         fullyConnectedLayer(numClasses,\cf5 \strokec5 'WeightLearnRateFactor'\cf2 \strokec2 ,20,\cf5 \strokec5 'BiasLearnRateFactor'\cf2 \strokec2 ,20)\cb1 \
\cb4         softmaxLayer\cb1 \
\cb4         classificationLayer];\cb1 \
\cb4     \cb1 \
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Requires images of size 227 by 227 by 3\cf2 \cb1 \strokec2 \
\
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     pixelRange = [-30 30];\cb1 \
\cb4     imageAugmenter = imageDataAugmenter( \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'RandXReflection'\cf2 \strokec2 ,true, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'RandXTranslation'\cf2 \strokec2 ,pixelRange, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'RandYTranslation'\cf2 \strokec2 ,pixelRange);\cb1 \
\cb4     augimdsTrain = augmentedImageDatastore(inputSize(1:2),imdsTrain, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'DataAugmentation'\cf2 \strokec2 ,imageAugmenter);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Automatically resize the validation images without data augmentation\cf2 \cb1 \strokec2 \
\cb4     augimdsValidation = augmentedImageDatastore(inputSize(1:2),imdsValidation);\cb1 \
\cb4     \cb1 \
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Training using the files from the merchdata set\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %Specifying the training options\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %Fast learning in new layers and slower learning in the others\cf2 \cb1 \strokec2 \
\cf3 \cb4 \strokec3 %'epoch' = full training cycle using the entire training data set \cf2 \cb1 \strokec2 \
\
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     options = trainingOptions(\cf5 \strokec5 'sgdm'\cf2 \strokec2 , \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'MiniBatchSize'\cf2 \strokec2 ,10, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'MaxEpochs'\cf2 \strokec2 ,6, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'InitialLearnRate'\cf2 \strokec2 ,1e-4, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'Shuffle'\cf2 \strokec2 ,\cf5 \strokec5 'every-epoch'\cf2 \strokec2 , \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'ValidationData'\cf2 \strokec2 ,augimdsValidation, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'ValidationFrequency'\cf2 \strokec2 ,3, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'Verbose'\cf2 \strokec2 ,false, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4         \cf5 \strokec5 'Plots'\cf2 \strokec2 ,\cf5 \strokec5 'training-progress'\cf2 \strokec2 );\cb1 \
\
\
\cb4     \cf3 \strokec3 %Training the network consisting of transferred and new layers.\cf2 \cb1 \strokec2 \
\cb4     \cf3 \strokec3 %Opens in a new window - realtime\cf2 \cb1 \strokec2 \
\cb4     netTransfer = trainNetwork(augimdsTrain,layers,options);\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Classifying the validation images using the network\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     [YPred,scores] = classify(netTransfer,augimdsValidation);\cb1 \
\cb4     \cb1 \
\cb4     idx = randperm(numel(imdsValidation.Files),4);\cb1 \
\cb4     figure\cb1 \
\cb4     \cf6 \strokec6 for \cf2 \strokec2 i = 1:4\cb1 \
\cb4         subplot(2,2,i)\cb1 \
\cb4         I = readimage(imdsValidation,idx(i));\cb1 \
\cb4         imshow(I)\cb1 \
\cb4         label = YPred(idx(i));\cb1 \
\cb4         title(string(label));\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Checking Accuracy\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Display four validation images with predicted labels.\cf2 \cb1 \strokec2 \
\cb4     YValidation = imdsValidation.Labels;\cb1 \
\cb4     accuracy = mean(YPred == YValidation)\cb1 \
\cb4   \cb1 \
\
\
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 KNN
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Check and load data\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf6 \strokec6 if \cf2 \strokec2 ~exist(\cf5 \strokec5 './MerchData'\cf2 \strokec2 , \cf5 \strokec5 'dir'\cf2 \strokec2 )\cb1 \
\cb4         error(\cf5 \strokec5 'You need to download MerchData.zip from Moodle and unzip it into the same directory as this live script'\cf2 \strokec2 );\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\cb4     \cb1 \
\cb4     \cb1 \
\cb4     \cb1 \
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 % load the dataset\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     data = readcell(\cf5 \strokec5 './Coursework/MerchData.csv'\cf2 \strokec2 );\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 % <my comment removed>:\cf2 \cb1 \strokec2 \
\cb4     data(1:1:10, 1:1:end)\cb1 \
\cb4     data(1, :) = [];\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 % <my comment removed>:\cf2 \cb1 \strokec2 \
\cb4     data = data(randperm(size(data,1)), :);\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %separating training and testing data\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     rng(0); \cf3 \strokec3 % please leave this re-seeding of the random number generator in place so we can compare results   \cf2 \cb1 \strokec2 \
\cb4     \cf3 \strokec3 %\cf2 \cb1 \strokec2 \
\cb4     nTest = round(0.4 * size(data,1))\cb1 \
\cb4     data_test = data(1:1:nTest, :);\cb1 \
\cb4     data_train = data(nTest+1:1:end, :);\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Creating labels\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Setting the label index to 2\cf2 \cb1 \strokec2 \
\cb4     label_index = 2;\cb1 \
\cb4     \cf3 \strokec3 %Populate 'test_labels' with a categorical containing test data and labels\cf2 \cb1 \strokec2 \
\cb4     test_labels = categorical(data_test(:, label_index));\cb1 \
\cb4     test_examples = cell2mat(data_test(:, 1:end~=label_index));\cb1 \
\cb4     \cf3 \strokec3 %Populate 'train_labels' with a categorical containing test data and labels\cf2 \cb1 \strokec2 \
\cb4     train_labels = categorical(data_train(:, label_index));\cb1 \
\cb4     train_examples = cell2mat(data_train(:, 1:end~=label_index));\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 % training the knn classifier\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cb1 \
\cb4     m_knn = fitcknn(train_examples, train_labels)\cb1 \
\cb4     \cb1 \
\cb4     m_nb = fitcnb(train_examples, train_labels)\cb1 \
\cb4     \cb1 \
\cb4     m_dt = fitctree(train_examples, train_labels)\cb1 \
\cb4     \cb1 \
\cb4     m_ann = fitcnet(train_examples, train_labels)\cb1 \
\cb4     \cb1 \
\cb4     m_svm = fitcecoc(train_examples, train_labels)\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %use trained classifier for prediction\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     predictions = predict(m_knn, test_examples);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     predictions1 = predict(m_nb, test_examples);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     predictions2 = predict(m_dt, test_examples);\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     predictions3 = predict(m_ann, test_examples);\cb1 \
\cb4     \cb1 \
\cb4    \cf3 \strokec3 %Using the trained classifier to predict using the 'test_examples'\cf2 \cb1 \strokec2 \
\cb4     predictions4 = predict(m_svm, test_examples);\cb1 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Evaluate classifiers performance\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     [c, order] = confusionmat(test_labels, predictions)\cb1 \
\cb4     \cb1 \
\cb4     \cf3 \strokec3 %Create and output a confusion chart using the test_labels and predictions\cf2 \cb1 \strokec2 \
\cb4     confusionchart(test_labels, predictions)\cb1 \
\cb4   \cb1 \
\cb4     confusionchart(test_labels, predictions1)\cb1 \
\
\
\cb4     confusionchart(test_labels, predictions2)\cb1 \
\
\
\cb4     confusionchart(test_labels, predictions3)\cb1 \
\
\
\cb4     confusionchart(test_labels, predictions4)\cb1 \
\
\
\cb4     \cf3 \strokec3 %Output accuracy\cf2 \cb1 \strokec2 \
\cb4     p = sum(diag(c)) / sum(c(1:1:end))\cb1 \
\
\
\pard\pardeftab720\partightenfactor0

\f0\b \cf2 Functions (in order of use):
\f1\b0 \
knn fit\
knn calculate distance\
knn predict\
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
get brightness - fin\
image to gray - \
get edges \
image gradient xy\
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
get hogs\
image gradient\
extract hog features\
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
get bag\
get words\
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
\pard\pardeftab720\partightenfactor0

\f2 \cf6 \cb4 \strokec6 function \cf2 \strokec2 b = get_brightness(im)\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     size(im)\cb1 \
\cb4     x = size(im)\cb1 \
\cb4                \cb1 \
\cb4     n = x(1,2) * x(1,2)\cb1 \
\cb4                 \cb1 \
\cb4     \cf3 \strokec3 %Output the image\cf2 \cb1 \strokec2 \
\cb4     imshow(im);\cb1 \
\cb4     \cf3 \strokec3 %calculate average brightness of an image\cf2 \cb1 \strokec2 \
\cb4     brightness = mean2(im)\cb1 \
\cb4     imageArray = []\cb1 \
\cb4     imageArray = im\cb1 \
\cb4     summedImage = sum(imageArray(),\cf5 \strokec5 "all"\cf2 \strokec2 )\cb1 \
\cb4     finbri = summedImage / n\cb1 \
\cb4     b = finbri\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb4 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\
\
\cf6 \cb4 \strokec6 function \cf2 \strokec2 edges = get_edges(im)\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     edges = [0 0];\cb1 \
\
\
\cb4     surf(im, \cf5 \strokec5 'EdgeColor'\cf2 \strokec2 , \cf5 \strokec5 'none'\cf2 \strokec2 );\cb1 \
\
\
\cb4     im = im2gray(im);\cb1 \
\cb4     imshow(im);\cb1 \
\cb4     [Gx, Gy] = imgradientxy(im, \cf5 \strokec5 'Prewitt'\cf2 \strokec2 );\cb1 \
\
\
\cb4     abs(Gy);\cb1 \
\cb4     abs(Gx);\cb1 \
\
\
\cb4     Gy(Gy>45)\cb1 \
\cb4     Gx(Gx<45)\cb1 \
\
\
\cb4     imshow(Gy)\cb1 \
\cb4     imshow(Gx)\cb1 \
\cb4     \cb1 \
\cb4     Gy1 = sum(Gy);\cb1 \
\cb4     Gx1 = sum(Gx);\cb1 \
\
\
\cb4     edges = [Gy Gx];\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb4 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\
\
\cf6 \cb4 \strokec6 function \cf2 \strokec2 h = get_hogs(im)\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     h = [];\cb1 \
\
\
\cb4     [Gx, Gy] = imgradientxy(im, \cf5 \strokec5 'Prewitt'\cf2 \strokec2 );\cb1 \
\cb4     [Gmag, Gdir] = imgradient(Gx, Gy);\cb1 \
\cb4     \cb1 \
\cb4     imagesc(Gmag);\cb1 \
\cb4     imagesc(Gdir);\cb1 \
\cb4     \cb1 \
\cb4     CELLSIZE = [16 16];\cb1 \
\cb4     [h, v] = extractHOGFeatures(im, \cf5 \strokec5 'CellSize'\cf2 \strokec2 , CELLSIZE, \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'BlockSize'\cf2 \strokec2 , [floor(size(im,1)/CELLSIZE(1)) floor(size(im,2)/CELLSIZE(2))], \cf6 \strokec6 ...\cf2 \cb1 \strokec2 \
\cb4     \cf5 \strokec5 'UseSignedOrientation'\cf2 \strokec2 , true);\cb1 \
\cb4     \cb1 \
\cb4     imshow(im);\cb1 \
\cb4     hold(\cf5 \strokec5 'on'\cf2 \strokec2 )\cb1 \
\cb4     v.plot();\cb1 \
\cb4     h\cb1 \
\cb4     \cb1 \
\cb4     hold(\cf5 \strokec5 "off"\cf2 \strokec2 )\cf3 \strokec3 %bar chart will not show without this\cf2 \cb1 \strokec2 \
\cb4     bar(h)\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb4 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\
\
\cf6 \cb4 \strokec6 function \cf2 \strokec2 words = get_words(H)\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     rng(0);\cb1 \
\
\
\cb4     words = [];\cb1 \
\cb4     bag= [];\cb1 \
\
\
\cb4     words = bagOfFeatures(training);\cb1 \
\cb4     im = training.readimage(1);\cb1 \
\cb4     im = im2gray(im);\cb1 \
\cb4     bag = words.encode(im);\cb1 \
\
\
\cb4     words = sum(bag)\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb4 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf3 \cb4 \strokec3 %Extension Functions\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb4     \cf6 \strokec6 function \cf2 \strokec2 im_g = my_im2gray(im)\cb1 \
\cb4     \cb1 \
\cb4         im_g = [];\cb1 \
\cb4     \cb1 \
\cb4         img = im; \cf3 \strokec3 % RGB image\cf2 \cb1 \strokec2 \
\cb4         \cf3 \strokec3 %img = ind2rgb(im,map);\cf2 \cb1 \strokec2 \
\cb4         img = im2double(img); \cf3 \strokec3 % convert image to double datatype\cf2 \cb1 \strokec2 \
\cb4         r = img(:,:,1);\cb1 \
\cb4         g = img(:,:,2);\cb1 \
\cb4         b = img(:,:,3);\cb1 \
\cb4             \cb1 \
\cb4         \cf3 \strokec3 %gray_image; % image you get after adding three channels\cf2 \cb1 \strokec2 \
\cb4         gray_image = im2uint8(gray_image);\cb1 \
\cb4     \cb1 \
\cb4         im_g = gray_image\cb1 \
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\
\
\
\cb4     \cf6 \strokec6 function \cf2 \strokec2 [Gmag, Gdir] = my_imgradient(Gx, Gy)\cb1 \
\
\
\cb4     Gmag = [];\cb1 \
\cb4     Gdir = []; \cb1 \
\cb4     \cb1 \
\cb4     \cb1 \
\
\
\cb4     \cf6 \strokec6 end\cf2 \cb1 \strokec2 \
\
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
\pard\pardeftab720\partightenfactor0

\f2 \cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf2 \
}